'use strict';

const g_db = require('@arangodb').db;
const g_lib = require('./support');
const g_graph = require('@arangodb/general-graph')._graph('sdmsg');
const g_proc = require('./process');
var g_internal = require("internal");

var tasks_func = function() {
    var obj = {};

    // ----------------------- ALLOC CREATE ----------------------------

    obj.taskInitAllocCreate = function(a_client, a_repo_id, a_subject_id, a_data_limit, a_rec_limit) {
        console.log("taskInitAllocCreate");

        // Check if repo and subject exist
        if (!g_db._exists(a_repo_id))
            throw [g_lib.ERR_NOT_FOUND, "Repo, '" + a_repo_id + "', does not exist"];

        if (!g_db._exists(a_subject_id))
            throw [g_lib.ERR_NOT_FOUND, "Subject, '" + a_subject_id + "', does not exist"];

        // Check for proper permissions
        g_lib.ensureAdminPermRepo(a_client, a_repo_id);

        // Check if there is already a matching allocation
        var alloc = g_db.alloc.firstExample({
            _from: a_subject_id,
            _to: a_repo_id
        });
        if (alloc)
            throw [g_lib.ERR_INVALID_PARAM, "Subject, '" + a_subject_id + "', already has as allocation on " + a_repo_id];

        // Check if there is an existing alloc task to involving the same allocation (repo + subject)
        var res = g_db._query("for v, e in 1..1 inbound @repo lock filter e.context == @subj && v.type == @type return v._id", {
            repo: a_repo_id,
            subj: a_subject_id,
            type: g_lib.TT_ALLOC_CREATE
        });

        if (res.hasNext()) {
            throw [g_lib.ERR_IN_USE, "A duplicate allocation create task was found."];
        }

        var repo = g_db.repo.document(a_repo_id);
        var path = repo.path + (a_subject_id.charAt(0) == "p" ? "project/" : "user/") + a_subject_id.substr(2) + "/";
        var state = {
            repo_id: a_repo_id,
            subject: a_subject_id,
            data_limit: a_data_limit,
            rec_limit: a_rec_limit,
            repo_path: path
        };
        var task = obj._createTask(a_client._id, g_lib.TT_ALLOC_CREATE, 2, state);

        if (g_proc._lockDepsGeneral(task._id, [{
                id: a_repo_id,
                lev: 1,
                ctx: a_subject_id
            }, {
                id: a_subject_id,
                lev: 0
            }])) {
            task = g_db.task.update(task._id, {
                status: g_lib.TS_BLOCKED,
                msg: "Queued"
            }, {
                returnNew: true,
                waitForSync: true
            }).new;
        }

        return {
            "task": task
        };
    };

    obj.taskRunAllocCreate = function(a_task) {
        console.log("taskRunAllocCreate");

        var reply, state = a_task.state;

        // No rollback functionality
        if (a_task.step < 0)
            return;

        if (a_task.step === 0) {
            reply = {
                cmd: g_lib.TC_ALLOC_CREATE,
                params: {
                    repo_id: state.repo_id,
                    repo_path: state.repo_path
                },
                step: a_task.step
            };
        } else {
            // Create allocation edge and finish

            obj._transact(function() {
                //console.log("saving alloc:", state.subject, state.repo_id, state.data_limit, state.rec_limit,  0, 0, state.repo_path );

                g_db.alloc.save({
                    _from: state.subject,
                    _to: state.repo_id,
                    data_limit: state.data_limit,
                    rec_limit: state.rec_limit,
                    rec_count: 0,
                    data_size: 0,
                    path: state.repo_path
                });
                reply = {
                    cmd: g_lib.TC_STOP,
                    params: obj.taskComplete(a_task._id, true)
                };
            }, [], ["task", "alloc"], ["lock", "block"]);
        }

        return reply;
    };


    // ----------------------- ALLOC DELETE ----------------------------

    obj.taskInitAllocDelete = function(a_client, a_repo_id, a_subject_id) {
        console.log("taskInitAllocDelete");

        if (!g_db._exists(a_repo_id))
            throw [g_lib.ERR_NOT_FOUND, "Repo, '" + a_repo_id + "', does not exist"];

        if (!g_db._exists(a_subject_id))
            throw [g_lib.ERR_NOT_FOUND, "Subject, '" + a_subject_id + "', does not exist"];

        var repo = g_db.repo.document(a_repo_id);

        g_lib.ensureAdminPermRepo(a_client, a_repo_id);

        var alloc = g_db.alloc.firstExample({
            _from: a_subject_id,
            _to: a_repo_id
        });
        if (!alloc)
            throw [g_lib.ERR_NOT_FOUND, "Subject, '" + a_subject_id + "', has no allocation on " + a_repo_id];

        var count = g_db._query("return length(for v, e in 1..1 inbound @repo loc filter e.uid == @subj return 1)", {
            repo: a_repo_id,
            subj: a_subject_id
        }).next();
        if (count)
            throw [g_lib.ERR_IN_USE, "Cannot delete allocation - records present"];

        // Check if there is an existing alloc task to involving the same allocation (repo + subject)
        var res = g_db._query("for v, e in 1..1 inbound @repo lock filter e.context == @subj && v.type == @type return v._id", {
            repo: a_repo_id,
            subj: a_subject_id,
            type: g_lib.TT_ALLOC_DEL
        });

        if (res.hasNext()) {
            throw [g_lib.ERR_IN_USE, "A duplicate allocation delete task was found."];
        }

        var path = repo.path + (a_subject_id.charAt(0) == "p" ? "project/" : "user/") + a_subject_id.substr(2) + "/";
        var state = {
            repo_id: a_repo_id,
            subject: a_subject_id,
            repo_path: path
        };
        var task = obj._createTask(a_client._id, g_lib.TT_ALLOC_DEL, 2, state);

        if (g_proc._lockDepsGeneral(task._id, [{
                id: a_repo_id,
                lev: 1,
                ctx: a_subject_id
            }, {
                id: a_subject_id,
                lev: 0
            }])) {
            task = g_db.task.update(task._id, {
                status: g_lib.TS_BLOCKED,
                msg: "Queued"
            }, {
                returnNew: true,
                waitForSync: true
            }).new;
        }

        return {
            "task": task
        };
    };

    obj.taskRunAllocDelete = function(a_task) {
        console.log("taskRunAllocDelete");

        var reply, state = a_task.state;

        // No rollback functionality
        if (a_task.step < 0)
            return;

        if (a_task.step == 0) {
            // Delete alloc edge, request repo path delete
            obj._transact(function() {
                g_db.alloc.removeByExample({
                    _from: state.subject,
                    _to: state.repo_id
                });
                reply = {
                    cmd: g_lib.TC_ALLOC_DELETE,
                    params: {
                        repo_id: state.repo_id,
                        repo_path: state.repo_path
                    },
                    step: a_task.step
                };
            }, [], ["alloc"]);
        } else {
            // Complete task
            obj._transact(function() {
                reply = {
                    cmd: g_lib.TC_STOP,
                    params: obj.taskComplete(a_task._id, true)
                };
            }, [], ["task"], ["lock", "block"]);
        }

        return reply;
    };

    // ----------------------- DATA GET ----------------------------

    obj.taskInitDataGet = function(a_client, a_path, a_encrypt, a_res_ids, a_orig_fname, a_check) {
        console.log("taskInitDataGet");

        var result = g_proc.preprocessItems(a_client, null, a_res_ids, g_lib.TT_DATA_GET);

        if ((result.glob_data.length + result.ext_data.length) > 0 && !a_check) {
            var idx = a_path.indexOf("/");
            if (idx == -1)
                throw [g_lib.ERR_INVALID_PARAM, "Invalid destination path (must include endpoint)"];

            // Check for duplicate names
            if (a_orig_fname) {
                var fname, fnames = new Set();

                for (i in result.glob_data) {
                    fname = result.glob_data[i].source.substr(result.glob_data[i].source.lastIndexOf("/") + 1);
                    if (fnames.has(fname)) {
                        throw [g_lib.ERR_XFR_CONFLICT, "Duplicate filename(s) detected in transfer request."];
                    }

                    fnames.add(fname);
                }

                for (i in result.ext_data) {
                    fname = result.ext_data[i].source.substr(result.ext_data[i].source.lastIndexOf("/") + 1);
                    if (fnames.has(fname)) {
                        throw [g_lib.ERR_XFR_CONFLICT, "Duplicate filename(s) detected in transfer request."];
                    }

                    fnames.add(fname);
                }
            }

            var state = {
                    path: a_path,
                    encrypt: a_encrypt,
                    orig_fname: a_orig_fname,
                    glob_data: result.glob_data,
                    ext_data: result.ext_data
                },
                task = obj._createTask(a_client._id, g_lib.TT_DATA_GET, 2, state),
                i, dep_ids = [];

            // Determine if any other tasks use the selected records and queue this task if needed

            for (i in result.glob_data)
                dep_ids.push(result.glob_data[i]._id);

            for (i in result.ext_data)
                dep_ids.push(result.ext_data[i]._id);

            if (g_proc._processTaskDeps(task._id, dep_ids, 0, 0)) {
                task = g_db._update(task._id, {
                    status: g_lib.TS_BLOCKED,
                    msg: "Queued"
                }, {
                    returnNew: true
                }).new;
            }

            result.task = task;
        }

        return result;
    };

    obj.taskRunDataGet = function(a_task) {
        console.log("taskRunDataGet");

        var reply, state = a_task.state;

        // No rollback functionality
        if (a_task.step < 0)
            return;

        if (a_task.step == 0) {
            //console.log("taskRunDataGet - do setup");
            obj._transact(function() {
                // Generate transfer steps
                state.xfr = obj._buildTransferDoc(g_lib.TT_DATA_GET, state.glob_data, state.ext_data, state.path, state.orig_fname);
                // Update step info
                a_task.step = 1;
                a_task.steps = state.xfr.length + 2;
                // Update task
                g_db._update(a_task._id, {
                    step: a_task.step,
                    steps: a_task.steps,
                    state: {
                        xfr: state.xfr
                    },
                    ut: Math.floor(Date.now() / 1000)
                });
                // Fall-through to initiate first transfer
            }, ["repo", "loc"], ["task"]);
        }

        if (a_task.step < a_task.steps - 1) {
            //console.log("taskRunDataGet - do xfr");
            // Transfer data step

            var tokens = g_lib.getAccessToken(a_task.client);
            var params = {
                uid: a_task.client,
                type: a_task.type,
                encrypt: state.encrypt,
                acc_tok: tokens.acc_tok,
                ref_tok: tokens.ref_tok,
                acc_tok_exp_in: tokens.acc_tok_exp_in
            };
            params = Object.assign(params, state.xfr[a_task.step - 1]);

            reply = {
                cmd: g_lib.TC_RAW_DATA_TRANSFER,
                params: params,
                step: a_task.step
            };
        } else {
            //console.log("taskRunDataGet - complete task");
            obj._transact(function() {
                // Last step - complete task
                reply = {
                    cmd: g_lib.TC_STOP,
                    params: obj.taskComplete(a_task._id, true)
                };
            }, [], ["task"], ["lock", "block"]);
        }

        return reply;
    };

    // ----------------------- DATA PUT ----------------------------

    obj.taskInitDataPut = function(a_client, a_path, a_encrypt, a_ext, a_res_ids, a_check) {
        console.log("taskInitDataPut");

        var result = g_proc.preprocessItems(a_client, null, a_res_ids, g_lib.TT_DATA_PUT);

        if (result.glob_data.length > 0 && !a_check) {
            var idx = a_path.indexOf("/");
            if (idx == -1)
                throw [g_lib.ERR_INVALID_PARAM, "Invalid destination path (must include endpoint)"];

            var state = {
                path: a_path,
                encrypt: a_encrypt,
                ext: a_ext,
                glob_data: result.glob_data
            };
            var task = obj._createTask(a_client._id, g_lib.TT_DATA_PUT, 2, state);

            var dep_ids = [];
            for (var i in result.glob_data)
                dep_ids.push(result.glob_data[i].id);

            if (g_proc._processTaskDeps(task._id, dep_ids, 1, 0)) {
                task = g_db._update(task._id, {
                    status: g_lib.TS_BLOCKED,
                    msg: "Queued"
                }, {
                    returnNew: true
                }).new;
            }

            result.task = task;
        }

        return result;
    };

    obj.taskRunDataPut = function(a_task) {
        console.log("taskRunDataPut");
        var reply, state = a_task.state,
            params, xfr, retry;

        // No rollback functionality
        if (a_task.step < 0)
            return;

        console.log("taskRunDataPut begin Step: ", a_task.step);
        if (a_task.step == 0) {
            //console.log("taskRunDataPut - do setup");
            obj._transact(function() {
                // Generate transfer steps
                state.xfr = obj._buildTransferDoc(g_lib.TT_DATA_PUT, state.glob_data, null, state.path, false);
                // Update step info
                a_task.step = 1;
                a_task.steps = state.xfr.length + 3;
                // Update task
                g_db._update(a_task._id, {
                    step: a_task.step,
                    steps: a_task.steps,
                    state: {
                        xfr: state.xfr
                    },
                    ut: Math.floor(Date.now() / 1000)
                });
                // Fall-through to initiate first transfer
            }, ["repo", "loc"], ["task"]);
        }

        if (a_task.step < a_task.steps - 2) {
            //console.log("taskRunDataPut - do xfr");
            // Transfer data step

            var tokens = g_lib.getAccessToken(a_task.client);
            params = {
                uid: a_task.client,
                type: a_task.type,
                encrypt: state.encrypt,
                acc_tok: tokens.acc_tok,
                ref_tok: tokens.ref_tok,
                acc_tok_exp_in: tokens.acc_tok_exp_in
            };
            params = Object.assign(params, state.xfr[a_task.step - 1]);
            reply = {
                cmd: g_lib.TC_RAW_DATA_TRANSFER,
                params: params,
                step: a_task.step
            };
        } else if (a_task.step < a_task.steps - 1) {
            xfr = state.xfr[a_task.step - 2];

            // Update source, extention, manual/auto
            var rec = g_db.d.document(xfr.files[0].id),
                upd_rec = {};

            upd_rec.source = state.path;

            if (state.ext) {
                upd_rec.ext = state.ext;
                upd_rec.ext_auto = false;

                if (upd_rec.ext.charAt(0) != ".")
                    upd_rec.ext = "." + upd_rec.ext;

            } else if (rec.ext_auto) {
                var src = xfr.files[0].from;

                // Extention starts at LAST "." filename
                var pos = src.lastIndexOf(".");
                if (pos != -1) {
                    upd_rec.ext = src.substr(pos);
                } else {
                    upd_rec.ext = null;
                }
            }

            // Must do this in a retry loop in case of concurrent (non-put) updates
            retry = 10;

            for (;;) {
                try {
                    obj._transact(function() {
                        g_db._update(xfr.files[0].id, upd_rec, {
                            keepNull: false
                        });
                    }, [], ["d"], []);
                    break;
                } catch (e) {
                    if (--retry === 0 || !e.errorNum || e.errorNum != 1200) {
                        throw e;
                    }
                }
            }

            // Request data size update
            params = {
                repo_id: xfr.dst_repo_id,
                repo_path: xfr.dst_repo_path,
                ids: [xfr.files[0].id]
            };

            console.log("Printing params in task update size");
            console.log(params);
            reply = {
                cmd: g_lib.TC_RAW_DATA_UPDATE_SIZE,
                params: params,
                step: a_task.step
            };
        } else {
            //console.log("taskRunDataPut - complete task");
            obj._transact(function() {
                // Last step - complete task
                reply = {
                    cmd: g_lib.TC_STOP,
                    params: obj.taskComplete(a_task._id, true)
                };
            }, [], ["task"], ["lock", "block"]);
        }

        console.log("taskRunDataPut final reply");
        console.log(reply);
        return reply;
    };

    // ----------------------- ALLOCATION CHANGE ----------------------------

    /* Move records with managed data to the specified destination repository.
    Requires removing old "loc" edges and creating new ones between the affected
    records and the destination repository, and updating the statistics of all
    involved allocations. Unmanaged records do not use allocations and are ignored.
    */
    obj.taskInitRecAllocChg = function(a_client, a_proj_id, a_res_ids, a_dst_repo_id, a_check) {
        console.log("taskInitRecAllocChg");

        // Verify that client is owner, or has admin permission to project owner
        var owner_id;

        if (a_proj_id) {
            if (!g_db.p.exists(a_proj_id))
                throw [g_lib.ERR_INVALID_PARAM, "Project '" + a_proj_id + "' does not exist."];

            if (!g_lib.hasManagerPermProj(a_client, a_proj_id))
                throw [g_lib.ERR_PERM_DENIED, "Operation requires admin permissions to project."];

            owner_id = a_proj_id;
        } else {
            owner_id = a_client._id;
        }

        // Verify destination repo
        if (!g_db.repo.exists(a_dst_repo_id))
            throw [g_lib.ERR_INVALID_PARAM, "No such repo '" + a_dst_repo_id + "'"];

        // Verify client/owner has an allocation
        var alloc = g_db.alloc.firstExample({
            _from: owner_id,
            _to: a_dst_repo_id
        });
        if (!alloc)
            throw [g_lib.ERR_INVALID_PARAM, "No allocation on '" + a_dst_repo_id + "'"];

        var result = g_proc.preprocessItems({
            _id: owner_id,
            is_admin: false
        }, null, a_res_ids, g_lib.TT_REC_ALLOC_CHG);

        var i, loc, rec, rec_ids = [];

        result.tot_cnt = result.ext_data.length + result.glob_data.length;
        result.act_size = 0;

        for (i in result.glob_data) {
            rec = result.glob_data[i];
            loc = g_db.loc.firstExample({
                _from: rec.id
            });
            if (loc && loc._to != a_dst_repo_id) {
                rec_ids.push(rec.id);
                if (rec.size) {
                    result.act_size += rec.size;
                }
            }
        }

        result.act_cnt = rec_ids.length;
        result.data_limit = alloc.data_limit;
        result.data_size = alloc.data_size;
        result.rec_limit = alloc.rec_limit;
        result.rec_count = alloc.rec_count;

        // Stop if no record to process, or if this is just a check
        if (rec_ids.length === 0 || a_check)
            return result;

        var state = {
            encrypt: 1,
            glob_data: result.glob_data,
            dst_repo_id: a_dst_repo_id,
            owner_id: owner_id
        };
        var task = obj._createTask(a_client._id, g_lib.TT_REC_ALLOC_CHG, 2, state);

        if (g_proc._processTaskDeps(task._id, rec_ids, 1, 0)) {
            task = g_db._update(task._id, {
                status: g_lib.TS_BLOCKED,
                msg: "Queued"
            }, {
                returnNew: true
            }).new;
        }

        result.task = task;

        return result;
    };

    obj.taskRunRecAllocChg = function(a_task) {
        console.log("taskRunRecAllocChg");

        var reply, state = a_task.state,
            params, xfr, alloc, substep, xfrnum;

        // TODO Add rollback functionality
        if (a_task.step < 0) {
            var step = -a_task.step;
            //console.log("taskRunRecAllocChg - rollback step: ", step );

            if (step > 1 && step < a_task.steps - 1) {
                substep = (step - 2) % 4;
                xfrnum = Math.floor((step - 2) / 4);
                xfr = state.xfr[xfrnum];
                //console.log("taskRunRecAllocChg - rollback substep: ", substep );

                // Only action is to revert location in DB if transfer failed.
                if (substep > 0 && substep < 3) {
                    obj._transact(function() {
                        //console.log("taskRunRecAllocChg - recMoveRevert" );
                        obj.recMoveRevert(xfr.files);

                        // Update task step
                        a_task.step -= substep;
                        g_db._update(a_task._id, {
                            step: a_task.step,
                            ut: Math.floor(Date.now() / 1000)
                        });
                    }, [], ["loc", "task"]);
                }
            }

            return;
        }

        if (a_task.step == 0) {
            //console.log("taskRunRecAllocChg - do setup");
            obj._transact(function() {
                // Generate transfer steps
                state.xfr = obj._buildTransferDoc(g_lib.TT_REC_ALLOC_CHG, state.glob_data, null, state.dst_repo_id, false, state.owner_id);
                // Recalculate number of steps
                a_task.step = 1;
                a_task.steps = (state.xfr.length * 4) + 2;
                // Update task
                g_db._update(a_task._id, {
                    step: a_task.step,
                    steps: a_task.steps,
                    state: {
                        xfr: state.xfr
                    },
                    ut: Math.floor(Date.now() / 1000)
                });
                // Fall-through to initiate first transfer
            }, ["repo", "loc"], ["task"]);
        }

        if (a_task.step > 0 && a_task.step < a_task.steps - 1) {
            substep = (a_task.step - 1) % 4;
            xfrnum = Math.floor((a_task.step - 1) / 4);
            xfr = state.xfr[xfrnum];
            //console.log("taskRunRecAllocChg - xfr num",xfrnum,"substep",substep);

            switch (substep) {
                case 0:
                    //console.log("taskRunRecAllocChg - init move");
                    obj._transact(function() {
                        // Ensure allocation has sufficient record and data capacity
                        alloc = g_db.alloc.firstExample({
                            _from: state.owner_id,
                            _to: state.dst_repo_id
                        });
                        if (alloc.rec_count + xfr.files.length > alloc.rec_limit)
                            throw [g_lib.ERR_PERM_DENIED, "Allocation record count limit exceeded on " + state.dst_repo_id];
                        if (alloc.data_size + xfr.size > alloc.data_limit)
                            throw [g_lib.ERR_PERM_DENIED, "Allocation data size limit exceeded on " + state.dst_repo_id];

                        // Init record move
                        obj.recMoveInit(xfr.files, state.dst_repo_id);

                        // TEST ONLY
                        //throw [g_lib.ERR_INTERNAL_FAULT,"TEST ONLY ERROR"];

                        // Update task step
                        a_task.step += 1;
                        g_db._update(a_task._id, {
                            step: a_task.step,
                            ut: Math.floor(Date.now() / 1000)
                        });
                    }, [], ["loc", "task"]);
                    /* falls through */
                case 1:
                    //console.log("taskRunRecAllocChg - do xfr");
                    // Transfer data step

                    var tokens = g_lib.getAccessToken(a_task.client);
                    params = {
                        uid: a_task.client,
                        type: a_task.type,
                        encrypt: state.encrypt,
                        acc_tok: tokens.acc_tok,
                        ref_tok: tokens.ref_tok,
                        acc_tok_exp_in: tokens.acc_tok_exp_in
                    };
                    params = Object.assign(params, xfr);
                    reply = {
                        cmd: g_lib.TC_RAW_DATA_TRANSFER,
                        params: params,
                        step: a_task.step
                    };
                    break;
                case 2:
                    //console.log("taskRunRecAllocChg - finalize move");
                    obj._transact(function() {
                        // Init record move
                        obj.recMoveFini(xfr.files);

                        // Update task step
                        a_task.step += 1;
                        g_db._update(a_task._id, {
                            step: a_task.step,
                            ut: Math.floor(Date.now() / 1000)
                        });

                    }, [], ["loc", "alloc", "task"]);
                    /* falls through */
                case 3:
                    //console.log("taskRunRecAllocChg - delete old data");
                    // Request data size update
                    params = {
                        repo_id: xfr.src_repo_id,
                        repo_path: xfr.src_repo_path,
                    };
                    params.ids = [];
                    for (var i in xfr.files) {
                        params.ids.push(xfr.files[i].id);
                    }

                    reply = {
                        cmd: g_lib.TC_RAW_DATA_DELETE,
                        params: params,
                        step: a_task.step
                    };
                    break;
            }
        } else {
            //console.log("taskRunRecAllocChg - complete task");
            obj._transact(function() {
                // Last step - complete task
                reply = {
                    cmd: g_lib.TC_STOP,
                    params: obj.taskComplete(a_task._id, true)
                };
            }, [], ["task"], ["lock", "block"]);
        }

        return reply;
    };

    // ----------------------- OWNER CHANGE ----------------------------

    /* Move records to the specified new owner and destination collection and
    repository. Requires removing old "owner" and "loc" edges and creating new
    ones between the affected records and the destination owner and repository,
    and updating the statistics of all involved allocations. Unmanaged records
    do not use allocations, so only ownership is updated.
    */

    obj.taskInitRecOwnerChg = function(a_client, a_res_ids, a_dst_coll_id, a_dst_repo_id, a_check) {
        // Verify destination collection

        if (!g_db.c.exists(a_dst_coll_id))
            throw [g_lib.ERR_INVALID_PARAM, "No such collection '" + a_dst_coll_id + "'"];

        var owner_id = g_db.owner.firstExample({
            _from: a_dst_coll_id
        })._to;

        if (owner_id != a_client._id) {
            if ((owner_id.charAt(0) != 'p') || !g_lib.hasManagerPermProj(a_client, owner_id)) {
                var coll = g_db.c.document(a_dst_coll_id);

                if (!g_lib.hasPermissions(a_client, coll, g_lib.PERM_CREATE))
                    throw [g_lib.ERR_PERM_DENIED, "Operation requires CREATE permission on destination collection '" + a_dst_coll_id + "'"];
            }
        }

        var allocs;

        if (a_check) {
            // Get a list of available repos for client to pick from (there must be at least one)
            allocs = g_db.alloc.byExample({
                _from: owner_id
            }).toArray();
            if (!allocs.length)
                throw [g_lib.ERR_PERM_DENIED, "No allocations available for '" + owner_id + "'"];

            g_lib.sortAllocations(allocs);
        } else {
            // Verify destination repo
            if (!g_db.repo.exists(a_dst_repo_id))
                throw [g_lib.ERR_INVALID_PARAM, "No such repo '" + a_dst_repo_id + "'"];

            // Verify client/owner has an allocation
            if (!g_db.alloc.firstExample({
                    _from: owner_id,
                    _to: a_dst_repo_id
                }))
                throw [g_lib.ERR_INVALID_PARAM, "No allocation on '" + a_dst_repo_id + "'"];
        }

        var result = g_proc.preprocessItems(a_client, owner_id, a_res_ids, g_lib.TT_REC_OWNER_CHG);

        if (result.has_pub) {
            throw [g_lib.ERR_PERM_DENIED, "Owner change not allowed - selection contains public data."];
        }

        var i, loc, rec, deps = [];

        result.tot_cnt = result.ext_data.length + result.glob_data.length;
        result.act_size = 0;

        for (i in result.ext_data) {
            rec = result.ext_data[i];
            if (rec.owner != owner_id) {
                deps.push({
                    id: rec.id,
                    lev: 1
                });
            }
        }

        for (i in result.glob_data) {
            rec = result.glob_data[i];
            loc = g_db.loc.firstExample({
                _from: rec.id
            });
            if (loc.uid != owner_id || loc._to != a_dst_repo_id) {
                deps.push({
                    id: rec.id,
                    lev: 1
                });
                if (rec.size) {
                    result.act_size += rec.size;
                }
            }
        }

        result.act_cnt = deps.length;

        if (a_check) {
            for (i in allocs) {
                rec = allocs[i];
                rec.repo = rec._to;
                delete rec._id;
            }
            result.allocs = allocs;
        }

        // Stop if no record to process, or if this is just a check
        if (deps.length === 0 || a_check)
            return result;

        // Add additional dependencies for locks
        deps.push({
            id: a_dst_coll_id,
            lev: 0
        });
        deps.push({
            id: owner_id,
            lev: 0
        });
        deps.push({
            id: a_dst_repo_id,
            lev: 1,
            ctx: owner_id
        });

        var state = {
            encrypt: 1,
            ext_data: result.ext_data,
            glob_data: result.glob_data,
            dst_coll_id: a_dst_coll_id,
            dst_repo_id: a_dst_repo_id,
            owner_id: owner_id
        };
        var task = obj._createTask(a_client._id, g_lib.TT_REC_OWNER_CHG, 3, state);
        if (g_proc._lockDepsGeneral(task._id, deps)) {
            task = g_db._update(task._id, {
                status: g_lib.TS_BLOCKED,
                msg: "Queued"
            }, {
                returnNew: true
            }).new;
        }

        result.task = task;

        return result;
    };

    obj.taskRunRecOwnerChg = function(a_task) {
        console.log("taskRunRecOwnerChg");

        var reply, state = a_task.state,
            params, xfr, alloc, substep, xfrnum;

        // TODO Add rollback functionality
        if (a_task.step < 0) {
            var step = -a_task.step;
            //console.log("taskRunRecOwnerChg - rollback step: ", step );

            if (step > 1 && step < a_task.steps - 1) {
                substep = (step - 2) % 4;
                xfrnum = Math.floor((step - 2) / 4);
                xfr = state.xfr[xfrnum];
                //console.log("taskRunRecOwnerChg - rollback substep: ", substep );

                // Only action is to revert location in DB if transfer failed.
                if (substep > 0 && substep < 3) {
                    obj._transact(function() {
                        //console.log("taskRunRecOwnerChg - recMoveRevert" );
                        obj.recMoveRevert(xfr.files);

                        // Update task step
                        a_task.step -= substep;
                        g_db._update(a_task._id, {
                            step: a_task.step,
                            ut: Math.floor(Date.now() / 1000)
                        });
                    }, [], ["loc", "task"]);
                }
            }

            return;
        }

        if (a_task.step == 0) {
            //console.log("taskRunRecOwnerChg - do setup");
            obj._transact(function() {
                // Generate transfer steps
                state.xfr = obj._buildTransferDoc(g_lib.TT_REC_OWNER_CHG, state.glob_data, null, state.dst_repo_id, false, state.owner_id);
                // Update step info
                a_task.step = 1;
                a_task.steps = (state.xfr.length * 4) + 3;
                // Update task
                g_db._update(a_task._id, {
                    step: a_task.step,
                    steps: a_task.steps,
                    state: {
                        xfr: state.xfr
                    },
                    ut: Math.floor(Date.now() / 1000)
                });
                // Fall-through to initiate first transfer
            }, ["repo", "loc"], ["task"]);
        }

        if (a_task.step === 1) {
            //console.log("taskRunRecOwnerChg - move unmanaged records");
            obj._transact(function() {
                if (state.ext_data.length) {
                    obj.recMoveExt(state.ext_data, state.owner_id, state.dst_coll_id);
                }

                // Update task step
                a_task.step = 2;
                g_db._update(a_task._id, {
                    step: a_task.step,
                    ut: Math.floor(Date.now() / 1000)
                });
                // Fall-through to next step
            }, ["c"], ["loc", "alloc", "acl", "d", "owner", "item", "task", "a", "alias"]);
        }

        if (a_task.step > 1 && a_task.step < a_task.steps - 1) {
            substep = (a_task.step - 2) % 4;
            xfrnum = Math.floor((a_task.step - 2) / 4);
            xfr = state.xfr[xfrnum];
            //console.log("taskRunRecOwnerChg - xfr num",xfrnum,"substep",substep);

            switch (substep) {
                case 0:
                    //console.log("taskRunRecOwnerChg - init move");
                    obj._transact(function() {
                        // Ensure allocation has sufficient record and data capacity
                        alloc = g_db.alloc.firstExample({
                            _from: state.owner_id,
                            _to: state.dst_repo_id
                        });
                        if (alloc.rec_count + xfr.files.length > alloc.rec_limit)
                            throw [g_lib.ERR_PERM_DENIED, "Allocation record count limit exceeded on " + state.dst_repo_id];
                        if (alloc.data_size + xfr.size > alloc.data_limit)
                            throw [g_lib.ERR_PERM_DENIED, "Allocation data size limit exceeded on " + state.dst_repo_id];

                        // Init record move
                        obj.recMoveInit(xfr.files, state.dst_repo_id, state.owner_id, state.dst_coll_id);

                        // Update task step
                        a_task.step += 1;
                        g_db._update(a_task._id, {
                            step: a_task.step,
                            ut: Math.floor(Date.now() / 1000)
                        });
                    }, [], ["loc", "task"]);
                    /* falls through */
                case 1:
                    //console.log("taskRunRecOwnerChg - do xfr");
                    // Transfer data step

                    var tokens = g_lib.getAccessToken(a_task.client);
                    params = {
                        uid: a_task.client,
                        type: a_task.type,
                        encrypt: state.encrypt,
                        acc_tok: tokens.acc_tok,
                        ref_tok: tokens.ref_tok,
                        acc_tok_exp_in: tokens.acc_tok_exp_in
                    };
                    params = Object.assign(params, xfr);
                    reply = {
                        cmd: g_lib.TC_RAW_DATA_TRANSFER,
                        params: params,
                        step: a_task.step
                    };
                    break;
                case 2:
                    //console.log("taskRunRecOwnerChg - finalize move");
                    obj._transact(function() {
                        // Init record move
                        obj.recMoveFini(xfr.files);

                        // Update task step
                        a_task.step += 1;
                        g_db._update(a_task._id, {
                            step: a_task.step,
                            ut: Math.floor(Date.now() / 1000)
                        });

                    }, ["c"], ["loc", "alloc", "acl", "d", "owner", "item", "task", "a", "alias"]);
                    /* falls through */
                case 3:
                    //console.log("taskRunRecOwnerChg - delete old data");
                    // Request data size update
                    params = {
                        repo_id: xfr.src_repo_id,
                        repo_path: xfr.src_repo_path,
                    };
                    params.ids = [];
                    for (var i in xfr.files) {
                        params.ids.push(xfr.files[i].id);
                    }

                    reply = {
                        cmd: g_lib.TC_RAW_DATA_DELETE,
                        params: params,
                        step: a_task.step
                    };
                    break;
            }
        } else {
            //console.log("taskRunRecOwnerChg - complete task");
            obj._transact(function() {
                // Last step - complete task
                reply = {
                    cmd: g_lib.TC_STOP,
                    params: obj.taskComplete(a_task._id, true)
                };
            }, [], ["task"], ["lock", "block"]);
        }

        return reply;
    };

    obj.taskInitRecCollDelete = function(a_client, a_ids) {
        console.log("taskInitRecCollDelete start", Date.now());

        var result = g_proc.preprocessItems(a_client, null, a_ids, g_lib.TT_REC_DEL);

        if (result.has_pub) {
            throw [g_lib.ERR_PERM_DENIED, "Deletion not allowed - selection contains public data."];
        }

        var i, rec_ids = [];

        //console.log("Extern recs:", result.ext_data.length, ", Globus recs:", result.glob_data.length );

        for (i in result.ext_data) {
            rec_ids.push(result.ext_data[i].id);
        }

        for (i in result.glob_data)
            rec_ids.push(result.glob_data[i].id);

        obj._ensureExclusiveAccess(rec_ids);

        var state = {};

        //console.log("ext_data:",result.ext_data);
        //console.log("glob_data:",result.glob_data);
        //console.log("rec_ids:",rec_ids);
        //console.log("del coll:",result.coll);
        //throw [1,"Stop for debug"];

        // For deleted collections, unlink all contained items
        if (result.coll.length) {
            state.del_coll = result.coll;
            for (i in result.coll) {
                g_db.item.removeByExample({
                    _to: result.coll[i]
                });
            }
        }

        state.del_rec = [];

        if (result.ext_data.length) {
            for (i in result.ext_data) {
                state.del_rec.push(result.ext_data[i].id);
                g_db.item.removeByExample({
                    _to: result.ext_data[i].id
                });
            }
        }

        if (result.glob_data.length) {
            state.del_data = obj._buildDeleteDoc(result.glob_data);

            for (i in result.glob_data) {
                state.del_rec.push(result.glob_data[i].id);
                g_db.item.removeByExample({
                    _to: result.glob_data[i].id
                });
            }
        } else {
            state.del_data = [];
        }

        result.task = obj._createTask(a_client._id, g_lib.TT_REC_DEL, state.del_data.length + 2, state);

        //console.log("taskInitRecCollDelete finished",Date.now());
        return result;
    };

    obj.taskRunRecCollDelete = function(a_task) {
        console.log("taskRunRecCollDelete");

        var i, reply, state = a_task.state,
            retry;

        // No rollback functionality
        if (a_task.step < 0)
            return;

        if (a_task.step == 0) {
            retry = 10;

            for (;;) {
                try {
                    obj._transact(function() {
                        //console.log("Del collections",Date.now());

                        for (i in state.del_coll) {
                            // TODO Adjust for collection limit on allocation
                            obj._deleteCollection(state.del_coll[i]);
                        }

                        //console.log("Del records",Date.now());

                        // Delete records with no data
                        if (state.del_rec.length) {
                            obj._deleteDataRecords(state.del_rec);
                        }

                        // Update task step
                        a_task.step += 1;
                        g_db._update(a_task._id, {
                            step: a_task.step,
                            ut: Math.floor(Date.now() / 1000)
                        });
                    }, [], ["d", "c", "a", "alias", "owner", "item", "acl", "loc", "alloc", "t", "top", "dep", "n", "note", "task", "tag", "sch"]);
                    break;
                } catch (e) {
                    if (--retry == 0 || !e.errorNum || e.errorNum != 1200) {
                        throw e;
                    }
                }
            }
            // Continue to next step
        }

        if (a_task.step < a_task.steps - 1) {
            //console.log("taskRunRecCollDelete - del", a_task.step, Date.now() );
            reply = {
                cmd: g_lib.TC_RAW_DATA_DELETE,
                params: state.del_data[a_task.step - 1],
                step: a_task.step
            };
        } else {
            //console.log("taskRunRecCollDelete - complete task", Date.now() );
            obj._transact(function() {
                // Last step - complete task
                reply = {
                    cmd: g_lib.TC_STOP,
                    params: obj.taskComplete(a_task._id, true)
                };
            }, [], ["task"], ["lock", "block"]);
        }

        return reply;
    };

    // ----------------------- External Support Functions ---------------------


    /** @brief Delete projects and associated data
     *
     * Delete one or more projects. If a project has no allocations,
     * it can be deleted immediately. If a project has allocations and
     * raw data, the project can be deleted, but a task must be initialized
     * to delete the allocations. Deletion is an exclusive operation - if
     * any other tasks are using the project or associated data, the delete
     * operation will be denied.
     */
    obj.taskInitProjDelete = function(a_client, a_proj_ids) {
        var i, proj_id;

        // Verify existence and check permission
        for (i in a_proj_ids) {
            proj_id = a_proj_ids[i];
            if (!g_db.p.exists(proj_id))
                throw [g_lib.ERR_INVALID_PARAM, "No such project '" + proj_id + "'"];

            g_lib.ensureAdminPermProj(a_client, proj_id);
        }

        obj._ensureExclusiveAccess(a_proj_ids);

        var allocs, alloc, gr;
        var state = {
            proj_ids: [],
            allocs: []
        };

        // For each project, determine allocation/raw data status and take appropriate actions
        for (i in a_proj_ids) {
            proj_id = a_proj_ids[i];

            state.proj_ids.push(proj_id);

            allocs = g_db.alloc.byExample({
                _from: proj_id
            });
            while (allocs.hasNext()) {
                alloc = allocs.next();
                state.allocs.push({
                    repo_id: alloc._to,
                    repo_path: alloc.path
                });
            }

            // Remove owner, admins, members to prevent access
            g_db.owner.removeByExample({
                _from: proj_id
            });
            g_db.admin.removeByExample({
                _from: proj_id
            });

            gr = g_db.g.byExample({
                uid: proj_id,
                gid: "members"
            });
            if (gr.hasNext()) {
                g_graph.g.remove(gr.next()._id);
            }
        }

        var result = {
            task: obj._createTask(a_client._id, g_lib.TT_PROJ_DEL, state.allocs.length + 2, state)
        };

        return result;
    };

    obj.taskRunProjDelete = function(a_task) {
        console.log("taskRunProjDelete");

        var reply, state = a_task.state;

        // No rollback functionality
        if (a_task.step < 0) {
            return;
        }

        if (a_task.step == 0) {
            obj._transact(function() {
                //console.log("Del projects",Date.now());

                for (var i in state.proj_ids) {
                    obj._projectDelete(state.proj_ids[i]);
                }

                // Update task step
                a_task.step += 1;
                g_db._update(a_task._id, {
                    step: a_task.step,
                    ut: Math.floor(Date.now() / 1000)
                });
            }, [], ["d", "c", "p", "a", "g", "alias", "owner", "item", "acl", "loc", "alloc", "t", "top", "dep", "n", "note", "task", "tag", "sch"]);

            // Continue to next step
        }

        if (a_task.step < a_task.steps - 1) {
            // Request repo path delete
            reply = {
                cmd: g_lib.TC_ALLOC_DELETE,
                params: state.allocs[a_task.step - 1],
                step: a_task.step
            };
        } else {
            // Complete task
            obj._transact(function() {
                reply = {
                    cmd: g_lib.TC_STOP,
                    params: obj.taskComplete(a_task._id, true)
                };
            }, [], ["task"], ["lock", "block"]);
        }

        return reply;
    };

    // ----------------------- External Support Functions ---------------------

    obj.taskGetRunFunc = function(a_task) {
        switch (a_task.type) {
            case g_lib.TT_DATA_GET:
                return obj.taskRunDataGet;
            case g_lib.TT_DATA_PUT:
                return obj.taskRunDataPut;
            case g_lib.TT_DATA_DEL:
                return obj.taskRunDataDelete;
            case g_lib.TT_REC_ALLOC_CHG:
                return obj.taskRunRecAllocChg;
            case g_lib.TT_REC_OWNER_CHG:
                return obj.taskRunRecOwnerChg;
            case g_lib.TT_REC_DEL:
                return obj.taskRunRecCollDelete;
            case g_lib.TT_ALLOC_CREATE:
                return obj.taskRunAllocCreate;
            case g_lib.TT_ALLOC_DEL:
                return obj.taskRunAllocDelete;
            case g_lib.TT_USER_DEL:
                return obj.taskRunUserDelete;
            case g_lib.TT_PROJ_DEL:
                return obj.taskRunProjDelete;
            default:
                throw [g_lib.ERR_INVALID_PARAM, "Invalid task type: " + a_task.type];
        }
    };

    // ----------------------- Internal Support Functions ---------------------

    obj.taskReady = function(a_task_id) {
        g_db._update(a_task_id, {
            status: g_lib.TS_RUNNING,
            msg: "Running",
            ut: Math.floor(Date.now() / 1000)
        }, {
            returnNew: true,
            waitForSync: true
        });
    };

    obj.taskComplete = function(a_task_id, a_success, a_msg) {
        console.log("taskComplete 1");
        var ready_tasks = [],
            dep, dep_blocks, blocks = g_db.block.byExample({
                _to: a_task_id
            });
        var time = Math.floor(Date.now() / 1000);

        console.log("taskComplete 2");

        while (blocks.hasNext()) {
            dep = blocks.next()._from;
            dep_blocks = g_db.block.byExample({
                _from: dep
            }).toArray();
            // If blocked task has only one block, then it's this task being finalized and will be able to run now
            if (dep_blocks.length === 1) {
                ready_tasks.push(dep);
                //console.log("taskComplete - task", dep, "ready");
                g_db.task.update(dep, {
                    status: g_lib.TS_READY,
                    msg: "Pending",
                    ut: time
                }, {
                    returnNew: true,
                    waitForSync: true
                });
            }
        }
        console.log("taskComplete 3");

        var doc;
        if (a_success) {
            doc = {
                status: g_lib.TS_SUCCEEDED,
                msg: "Finished"
            };
        } else {
            doc = {
                status: g_lib.TS_FAILED,
                msg: a_msg ? a_msg : "Failed (unknown reason)"
            };
        }

        doc.ut = time;

        console.log("taskComplete 4", doc );
        g_db.block.removeByExample({
            _to: a_task_id
        });
        g_db.lock.removeByExample({
            _from: a_task_id
        });
        console.log("taskComplete 5");
        var delay = 1;
        for (;;) {
            try {
                g_db.task.update(a_task_id, doc);
                break;
            } catch (e) {
                if (e.errorNum === 1200) {
                    if (delay > 64)
                        throw e;

                    //console.log("retry sleep");
                    g_internal.sleep(0.2 * delay);
                    //console.log("do retry");

                    delay *= 2;
                } else {
                    throw e;
                }
            }
        }
        console.log("taskComplete 6");

        return ready_tasks;
    };

    obj._transact = function(a_func, a_rdc = [], a_wrc = [], a_exc = []) {
        g_db._executeTransaction({
            collections: {
                read: a_rdc,
                write: a_wrc,
                exclusive: a_exc
            },
            lockTimeout: 0,
            waitForSync: true,
            action: a_func
        });
    };

    obj._createTask = function(a_client_id, a_type, a_steps, a_state) {
        var time = Math.floor(Date.now() / 1000);
        var obj = {
            type: a_type,
            status: g_lib.TS_READY,
            msg: "Pending",
            ct: time,
            ut: time,
            client: a_client_id,
            step: 0,
            steps: a_steps,
            state: a_state
        };
        var task = g_db.task.save(obj, {
            returnNew: true
        });
        return task.new;
    };

    obj._buildTransferDoc = function(a_mode, a_data, a_ext_data, a_remote, a_orig_fname, a_dst_owner) {
        /* Output per mode:
        GET:
            src_repo_xx - DataFed storage location
            dst_repo_xx - a_remote is full globus path
            files - from: data key, to: id + ext
            xfr_docs - one per source repo
        PUT:
            src_repo_xx - a_remote is full globus path
            dst_repo_xx - DataFed storage location
            files - from: filename, to: data key
            xfr_docs - one (only one file per put allowed)
        ALLOC_CHG:
            src_repo_xx - DataFed storage location
            dst_repo_xx - a_remote is dest repo id
            files - from/to: data key
            xfr_docs - chunked per source repo and max data transfer size
        OWNER_CHG:
            src_repo_xx - DataFed storage location
            dst_repo_xx - a_remote is dest repo id
            files - from/to: data key
            a_new_owner - new owner (w/ remote indicates dst allocation)
            xfr_docs - chunked per source repo and max data transfer size
        */

        console.log("_buildTransferDoc", a_mode, a_remote, a_orig_fname);

        var fnames, i, idx, file, rem_ep, rem_fname, rem_path, xfr, repo_map = {},
            src;

        if (a_mode == g_lib.TT_DATA_GET || a_mode == g_lib.TT_DATA_PUT) {
            idx = a_remote.indexOf("/");
            if (idx < 1)
                throw [g_lib.ERR_INVALID_PARAM, "Invalid remote path (must include endpoint)"];

            //console.log("rem idx:",idx);

            rem_ep = a_remote.substr(0, idx);
            rem_path = a_remote.substr(idx);

            //console.log("rem ep:",rem_ep);
            //console.log("rem path:",rem_path);

            if (a_mode == g_lib.TT_DATA_GET) {
                if (rem_path.charAt(rem_path.length - 1) != "/")
                    rem_path += "/";
            } else if (a_mode == g_lib.TT_DATA_PUT) {
                idx = rem_path.lastIndexOf("/", rem_path.length - 1);
                //console.log("new idx:",idx);

                rem_fname = rem_path.substr(idx + 1);
                rem_path = rem_path.substr(0, idx + 1);
                //console.log("rem_fname",rem_fname);
                //console.log("rem_path",rem_path);
            }
        } else {
            //console.log("should not be here!",a_mode, g_lib.TT_DATA_GET, g_lib.TT_DATA_PUT);

            var repo = g_db.repo.document(a_remote);
            rem_ep = repo.endpoint;
            rem_path = repo.path + (a_dst_owner.charAt(0) == "u" ? "user/" : "project/") + a_dst_owner.substr(2) + "/";
        }

        if (a_mode == g_lib.TT_DATA_GET) {
            fnames = new Set();
        }

        if (a_data.length) {
            var loc, locs = g_db._query("for i in @data for v,e in 1..1 outbound i loc return { d_id: i._id, d_sz: i.size, d_ext: i.ext, d_src: i.source, r_id: v._id, r_ep: v.endpoint, r_path: v.path, uid: e.uid }", {
                data: a_data
            });

            //console.log("locs hasNext",locs.hasNext());

            while (locs.hasNext()) {
                loc = locs.next();
                //console.log("loc",loc);

                file = {
                    id: loc.d_id,
                    size: loc.d_sz
                };

                switch (a_mode) {
                    case g_lib.TT_DATA_GET:
                        file.from = loc.d_id.substr(2);
                        if (a_orig_fname) {
                            file.to = loc.d_src.substr(loc.d_src.lastIndexOf("/") + 1);
                            if (fnames.has(file.to)) {
                                throw [g_lib.ERR_XFR_CONFLICT, "Duplicate filename(s) detected in transfer request."];
                            }

                            fnames.add(file.to);

                            /*if ( loc.d_ext ){
                                idx = src.indexOf(".");
                                if ( idx > 0 ){
                                    src = src.substr(0,idx);
                                }
                                file.to = src + loc.d_ext;
                            }else{
                                file.to = src;
                            }*/
                        } else {
                            file.to = file.from + (loc.d_ext ? loc.d_ext : "");
                        }
                        break;
                    case g_lib.TT_DATA_PUT:
                        file.from = rem_fname;
                        file.to = loc.d_id.substr(2);
                        break;
                    case g_lib.TT_REC_ALLOC_CHG:
                    case g_lib.TT_REC_OWNER_CHG:
                        file.from = loc.d_id.substr(2);
                        file.to = file.from;
                        break;
                }

                //console.log("file:",file);

                if (loc.r_id in repo_map) {
                    repo_map[loc.r_id].files.push(file);
                } else {
                    repo_map[loc.r_id] = {
                        repo_id: loc.r_id,
                        repo_ep: loc.r_ep,
                        repo_path: loc.r_path + (loc.uid.charAt(0) == "u" ? "user/" : "project/") + loc.uid.substr(2) + "/",
                        files: [file]
                    };
                }
            }
        }

        // Process external data (only supported for GET)
        if (a_ext_data && a_ext_data.length) {
            var edat, ep;

            // Add external endpoints to repo_map using endpoint as ID

            for (i in a_ext_data) {
                edat = a_ext_data[i];
                file = {
                    id: edat.id,
                    size: edat.size
                };

                idx = edat.source.indexOf("/");
                if (idx < 0) {
                    throw [g_lib.ERR_INVALID_PARAM, "Invalid external source path: " + edat.source];
                }
                ep = edat.source.substr(0, idx);
                src = edat.source.substr(idx);
                file.from = src;
                if (a_orig_fname) {
                    idx = src.lastIndexOf("/");
                    if (idx < 0) {
                        throw [g_lib.ERR_INVALID_PARAM, "Invalid external source path: " + edat.source];
                    }
                    file.to = src.substr(idx + 1);
                    if (fnames.has(file.to)) {
                        throw [g_lib.ERR_XFR_CONFLICT, "Duplicate filename(s) detected in transfer request."];
                    }
                } else {
                    file.to = file.id.substr(2);
                }

                if (ep in repo_map) {
                    repo_map[ep].files.push(file);
                } else {
                    repo_map[ep] = {
                        repo_id: 0, // ID 0 indicates external endpoint
                        files: [file]
                    };
                }
            }
        }

        //console.log("repo map len",Object.keys(repo_map).length);

        var rm, xfr_docs = [];

        if (a_mode == g_lib.TT_REC_ALLOC_CHG || a_mode == g_lib.TT_REC_OWNER_CHG) {
            var j, k, chunks, chunk_sz, files, sz;

            for (i in repo_map) {
                rm = repo_map[i];

                // Pack roughly equal transfer sizes into each transfer chunk/step

                // Sort files from largest to smallest
                rm.files.sort(function(a, b) {
                    return b.size - a.size;
                });

                chunks = [];
                chunk_sz = [];

                // Push files larger than chunk size into own transfers
                for (j = 0; j < rm.files.length; j++) {
                    file = rm.files[j];
                    if (file.size >= g_lib.GLOB_MAX_XFR_SIZE) {
                        //console.log("rec",file.id,"alone in xfr, sz:",file.size);
                        chunks.push([file]);
                        chunk_sz.push(file.size);
                    } else {
                        break;
                    }
                }

                // Remaining files are smaller than max chunk size
                // Build chunks by combining largest with smallest files
                for (; j < rm.files.length; j++) {
                    file = rm.files[j];
                    sz = file.size;
                    files = [file];
                    //console.log("rec",file.id,"first in xfr, sz:",file.size);

                    for (k = j + 1; k < rm.files.length;) {
                        file = rm.files[k];
                        if (sz + file.size <= g_lib.GLOB_MAX_XFR_SIZE) {
                            //console.log("rec",file.id,"added to xfr, sz:",file.size);
                            files.push(file);
                            sz += file.size;
                            rm.files.splice(k, 1);
                        } else {
                            //console.log("rec",file.id,"too big for xfr, sz:",file.size,"sum",sz + file.size,"max",g_lib.GLOB_MAX_XFR_SIZE);
                            k++;
                        }
                    }

                    chunks.push(files);
                    chunk_sz.push(sz);
                }

                for (j in chunks) {

                    xfr = {
                        src_repo_id: rm.repo_id,
                        src_repo_ep: rm.repo_ep,
                        src_repo_path: rm.repo_path,
                        dst_repo_id: a_remote,
                        dst_repo_ep: rem_ep,
                        dst_repo_path: rem_path,
                        size: chunk_sz[j]
                    };

                    xfr.files = chunks[j];
                    xfr_docs.push(xfr);
                }
            }
        } else {
            for (i in repo_map) {
                rm = repo_map[i];

                if (a_mode == g_lib.TT_DATA_GET) {
                    if (rm.repo_id === 0) {
                        xfr = {
                            src_repo_id: 0,
                            src_repo_ep: i,
                            src_repo_path: "",
                            dst_repo_ep: rem_ep,
                            dst_repo_path: rem_path
                        };
                    } else {
                        xfr = {
                            src_repo_id: rm.repo_id,
                            src_repo_ep: rm.repo_ep,
                            src_repo_path: rm.repo_path,
                            dst_repo_ep: rem_ep,
                            dst_repo_path: rem_path
                        };
                    }
                } else {
                    xfr = {
                        src_repo_ep: rem_ep,
                        src_repo_path: rem_path,
                        dst_repo_id: rm.repo_id,
                        dst_repo_ep: rm.repo_ep,
                        dst_repo_path: rm.repo_path
                    };
                }

                xfr.files = rm.files;
                xfr_docs.push(xfr);
            }
        }

        return xfr_docs;
    };


    obj._buildDeleteDoc = function(a_data) {
        var loc, locs, doc = [],
            repo_map = {};

        locs = g_db._query("for i in @data for v,e in 1..1 outbound i loc return { d_id: i._id, r_id: v._id, r_path: v.path, uid: e.uid }", {
            data: a_data
        });

        //console.log("locs hasNext",locs.hasNext());

        while (locs.hasNext()) {
            loc = locs.next();

            // Delete all files regardless of raw data size (may have 0 sized files)

            if (loc.r_id in repo_map) {
                repo_map[loc.r_id].ids.push(loc.d_id);
            } else {
                repo_map[loc.r_id] = {
                    repo_id: loc.r_id,
                    repo_path: loc.r_path + (loc.uid.charAt(0) == "u" ? "user/" : "project/") + loc.uid.substr(2) + "/",
                    ids: [loc.d_id]
                };
            }
        }

        for (var i in repo_map) {
            doc.push(repo_map[i]);
        }

        return doc;
    };

    /** @brief Deletes a collection record
     *
     * NOTE: DO NOT CALL THIS DIRECTLY - USED ONLY BY TASK/PROCESS CODE
     *
     * Does not recursively delete contained items.
     */
    obj._deleteCollection = function(a_id) {
        // Delete alias
        var tmp = g_db.alias.firstExample({
            _from: a_id
        });
        if (tmp) {
            g_graph.a.remove(tmp._to);
        }

        // Delete notes
        tmp = g_db.note.byExample({
            _from: a_id
        });
        while (tmp.hasNext()) {
            g_graph.n.remove(tmp.next()._to);
        }

        // Unlink/delete topic
        tmp = g_db.top.firstExample({
            _from: a_id
        });
        if (tmp)
            g_lib.topicUnlink(a_id);

        // Remove tags
        var doc = g_db.c.document(a_id);
        if (doc.tags && doc.tags.length)
            g_lib.removeTags(doc.tags);

        // Delete collection
        g_graph.c.remove(a_id);
    };


    /** @brief Deletes data records
     *
     * Deletes record and associated graph objects. Does not delete raw data
     * but does adjust allocation.
     */
    obj._deleteDataRecord = function(a_id) {
        //console.log( "delete rec", a_id );
        var doc = g_db.d.document(a_id);

        // Delete alias
        var tmp = g_db.alias.firstExample({
            _from: a_id
        });
        if (tmp) {
            g_graph.a.remove(tmp._to);
        }

        // Delete notes and all inherted notes
        tmp = g_db.note.byExample({
            _from: a_id
        });
        while (tmp.hasNext()) {
            g_lib.annotationDelete(tmp.next()._to);
        }

        // Remove tags
        if (doc.tags && doc.tags.length)
            g_lib.removeTags(doc.tags);

        // Update schema count
        if (doc.sch_id && g_db.sch.exists(doc.sch_id)) {
            var sch = g_db.sch.document(doc.sch_id);
            g_db._update(sch._id, {
                cnt: sch.cnt - 1
            });
        }

        // Update allocation
        var loc = g_db.loc.firstExample({
            _from: a_id
        });
        if (loc) {
            var alloc = g_db.alloc.firstExample({
                _from: doc.owner,
                _to: loc._to
            });
            if (alloc) {
                g_db.alloc.update(alloc._id, {
                    data_size: alloc.data_size - doc.size,
                    rec_count: alloc.rec_count - 1
                });
            }
        }

        // Delete data record
        g_graph.d.remove(a_id);
    };


    obj._deleteDataRecords = function(a_ids) {
        //console.log( "deleting records", Date.now() );
        var i, j, id, doc, tmp, loc, alloc, allocs = {};

        for (i in a_ids) {
            id = a_ids[i];
            doc = g_db.d.document(id);

            // Delete alias
            tmp = g_db.alias.firstExample({
                _from: id
            });
            if (tmp) {
                g_graph.a.remove(tmp._to);
            }

            // Delete notes and all inherted notes
            tmp = g_db.note.byExample({
                _from: id
            });
            while (tmp.hasNext()) {
                g_lib.annotationDelete(tmp.next()._to);
            }

            // Remove tags
            if (doc.tags && doc.tags.length) {
                g_lib.removeTags(doc.tags);
            }

            // Update schema count
            if (doc.sch_id && g_db.sch.exists(doc.sch_id)) {
                var sch = g_db.sch.document(doc.sch_id);
                g_db._update(sch._id, {
                    cnt: sch.cnt - 1
                });
            }

            // Update allocation
            loc = g_db.loc.firstExample({
                _from: id
            });
            if (loc) {
                if (!(doc.owner in allocs)) {
                    allocs[doc.owner] = {};
                }

                tmp = allocs[doc.owner][loc._to];

                if (!tmp) {
                    allocs[doc.owner][loc._to] = {
                        ct: 1,
                        sz: doc.size
                    };
                } else {
                    tmp.ct++;
                    tmp.sz += doc.size;
                }
            }

            // Delete data record
            g_graph.d.remove(id);
        }

        // /console.log( "allocation", allocs );
        //console.log( "updating allocation", Date.now() );

        for (i in allocs) {
            tmp = allocs[i];
            for (j in tmp) {
                alloc = g_db.alloc.firstExample({
                    _from: i,
                    _to: j
                });
                if (alloc) {
                    doc = tmp[j];
                    g_db.alloc.update(alloc._id, {
                        data_size: alloc.data_size - doc.sz,
                        rec_count: alloc.rec_count - doc.ct
                    });
                }
            }
        }

        //console.log( "deleting records finished", Date.now() );
    };


    /** @brief Deletes project immediately
     *
     * Deletes projects and associated graph objects.
     *
     * DO NOT USE ON PROJECTS WITH RAW DATA!!!!
     */
    obj._projectDelete = function(a_proj_id) {
        console.log("_projectDelete", a_proj_id);
        // Delete allocations
        g_db.alloc.removeByExample({
            _from: a_proj_id
        });

        // Delete all owned records (data, collections, groups, etc.)
        var id, rec_ids = g_db._query("for v in 1..1 inbound @proj owner filter !is_same_collection('a',v) return v._id", {
            proj: a_proj_id
        });

        while (rec_ids.hasNext()) {
            id = rec_ids.next();
            //console.log("del ",id);

            if (id.charAt(0) == "d") {
                obj._deleteDataRecord(id);
            } else if (id.charAt(0) == "c") {
                obj._deleteCollection(id);
            } else {
                g_graph[id.charAt(0)].remove(id);
            }
        }

        //console.log("del",a_proj_id);

        g_graph.p.remove(a_proj_id);
    };


    obj.recMoveInit = function(a_data, a_new_repo_id, a_new_owner_id, a_new_coll_id) {
        var loc;

        //console.log("recMoveInit", a_new_repo_id, a_new_owner_id, a_new_coll_id );

        for (var i in a_data) {
            loc = g_db.loc.firstExample({
                _from: a_data[i].id
            });

            var obj = {};

            // Skip records that are already on new allocation
            if (!a_new_owner_id && loc._to == a_new_repo_id)
                continue;

            obj.new_repo = a_new_repo_id;

            if (a_new_owner_id) {
                // Skip records that are have already been move to new owner
                if (loc.uid == a_new_owner_id)
                    continue;

                obj.new_owner = a_new_owner_id;
                obj.new_coll = a_new_coll_id;
            }

            g_db._update(loc._id, obj);
        }
    };


    obj.recMoveRevert = function(a_data) {
        var id, loc;

        for (var i in a_data) {
            id = a_data[i].id;
            //console.log("recMoveRevert", id );

            loc = g_db.loc.firstExample({
                _from: id
            });
            g_db._update(loc._id, {
                new_repo: null,
                new_owner: null,
                new_coll: null
            }, {
                keepNull: false
            });
        }
    };


    obj.recMoveFini = function(a_data) {
        var data, loc, new_loc, alloc, coll, alias, alias_pref, a, key;

        //console.log("recMoveFini" );

        for (var i in a_data) {
            data = a_data[i];

            loc = g_db.loc.firstExample({
                _from: data.id
            });

            //console.log("recMoveFini, id:", data.id, "loc:", loc );

            if (!loc.new_owner && !loc.new_repo)
                continue;

            if (loc.new_owner) {
                // Changing owner and repo

                if (!alias_pref) {
                    alias_pref = loc.new_owner.charAt(0) + ":" + loc.new_owner.substr(2) + ":";
                }

                // DEV-ONLY SANITY CHECKS:
                if (!loc.new_coll)
                    throw [g_lib.ERR_INTERNAL_FAULT, "Record '" + data.id + "' missing destination collection!"];

                if (!g_db.c.exists(loc.new_coll))
                    throw [g_lib.ERR_INTERNAL_FAULT, "Record '" + data.id + "' destination collection '" + loc.new_coll + "' does not exist!"];

                coll = g_db.c.document(loc.new_coll);

                if (coll.owner != loc.new_owner)
                    throw [g_lib.ERR_INTERNAL_FAULT, "Record '" + data.id + "' destination collection '" + loc.new_coll + "' not owner by new owner!"];

                // Clear all record ACLs
                g_db.acl.removeByExample({
                    _from: data.id
                });

                // Update record to new owner
                g_db._update(data.id, {
                    owner: loc.new_owner
                });

                // Move ownership edge
                g_db.owner.removeByExample({
                    _from: data.id
                });
                g_db.owner.save({
                    _from: data.id,
                    _to: loc.new_owner
                });

                // Move to new collection
                g_db.item.removeByExample({
                    _to: data.id
                });
                g_db.item.save({
                    _from: loc.new_coll,
                    _to: data.id
                });

                // Move owner edge of alias if alias present
                alias = g_db.alias.firstExample({
                    _from: data.id
                });
                if (alias) {
                    // remove old alias and all edges
                    g_graph.a.remove(alias._to);

                    // Create new alias (add suffix if collides with existing alias)
                    alias = alias_pref + alias._to.substr(alias._to.lastIndexOf(":") + 1);
                    for (a = 0;; a++) {
                        key = alias + (a > 0 ? "-" + a : "");
                        if (!g_db.a.exists({
                                _key: key
                            })) {
                            //console.log("try alias:",key);
                            g_db.a.save({
                                _key: key
                            });
                            break;
                        }
                    }
                    // If alias suffix, update record
                    if (a > 0) {
                        g_db.d.update(data.id, {
                            alias: key
                        });
                    }

                    g_db.alias.save({
                        _from: data.id,
                        _to: "a/" + key
                    });
                    g_db.owner.save({
                        _from: "a/" + key,
                        _to: loc.new_owner
                    });
                }
            }

            //rec = g_db.d.document( id );

            // Update old allocation stats
            alloc = g_db.alloc.firstExample({
                _from: loc.uid,
                _to: loc._to
            });
            if (!alloc)
                throw [g_lib.ERR_INTERNAL_FAULT, "Record '" + data.id + "' has mismatched allocation/location (cur)!"];

            //console.log("alloc:", alloc );
            //console.log("recMoveFini, adj src alloc to:", alloc.rec_count - 1, alloc.data_size - data.size );

            g_db._update(alloc._id, {
                rec_count: alloc.rec_count - 1,
                data_size: alloc.data_size - data.size
            });

            //console.log("update alloc:", alloc );

            // Update new allocation stats
            alloc = g_db.alloc.firstExample({
                _from: loc.new_owner ? loc.new_owner : loc.uid,
                _to: loc.new_repo
            });
            if (!alloc)
                throw [g_lib.ERR_INTERNAL_FAULT, "Record '" + data.id + "' has mismatched allocation/location (new)!"];

            //console.log("recMoveFini, adj dest alloc to:", alloc.rec_count + 1, alloc.data_size + data.size );

            g_db._update(alloc._id, {
                rec_count: alloc.rec_count + 1,
                data_size: alloc.data_size + data.size
            });

            // Create new edge to new owner/repo, delete old
            new_loc = {
                _from: loc._from,
                _to: loc.new_repo,
                uid: loc.new_owner ? loc.new_owner : loc.uid
            };
            g_db.loc.save(new_loc);
            g_db.loc.remove(loc);
        }
    };

    obj.recMoveExt = function(a_data, a_dst_owner_id, a_dst_coll_id) {
        if (!g_db.c.exists(a_dst_coll_id)) {
            throw [g_lib.ERR_INTERNAL_FAULT, "Destination collection '" + a_dst_coll_id + "' does not exist!"];
        }

        var data, alias, a, key,
            alias_pref = a_dst_owner_id.charAt(0) + ":" + a_dst_owner_id.substr(2) + ":",
            coll = g_db.c.document(a_dst_coll_id);

        if (coll.owner != a_dst_owner_id)
            throw [g_lib.ERR_INTERNAL_FAULT, "Destination collection '" + a_dst_coll_id + "' not owned by new owner!"];

        for (var i in a_data) {
            data = a_data[i];

            // Clear all record ACLs
            g_db.acl.removeByExample({
                _from: data.id
            });

            // Update record to new owner
            g_db._update(data.id, {
                owner: a_dst_owner_id
            });

            // Move ownership edge
            g_db.owner.removeByExample({
                _from: data.id
            });
            g_db.owner.save({
                _from: data.id,
                _to: a_dst_owner_id
            });

            // Move to new collection
            g_db.item.removeByExample({
                _to: data.id
            });
            g_db.item.save({
                _from: a_dst_coll_id,
                _to: data.id
            });

            // Move owner edge of alias if alias present
            alias = g_db.alias.firstExample({
                _from: data.id
            });
            if (alias) {
                // remove old alias and all edges
                g_graph.a.remove(alias._to);

                // Create new alias (add suffix if collides with existing alias)
                alias = alias_pref + alias._to.substr(alias._to.lastIndexOf(":") + 1);
                for (a = 0;; a++) {
                    key = alias + (a > 0 ? "-" + a : "");
                    if (!g_db.a.exists({
                            _key: key
                        })) {
                        //console.log("try alias:",key);
                        g_db.a.save({
                            _key: key
                        });
                        break;
                    }
                }
                // If alias suffix, update record
                if (a > 0) {
                    g_db.d.update(data.id, {
                        alias: key
                    });
                }

                g_db.alias.save({
                    _from: data.id,
                    _to: "a/" + key
                });
                g_db.owner.save({
                    _from: "a/" + key,
                    _to: a_dst_owner_id
                });
            }
        }
    };

    obj._ensureExclusiveAccess = function(a_ids) {
        //console.log("_ensureExclusiveAccess start", Date.now());
        var i, id, lock;
        for (i in a_ids) {
            id = a_ids[i];
            //console.log("_ensureExclusiveAccess",id);
            lock = g_db.lock.firstExample({
                _to: id
            });
            if (lock)
                throw [g_lib.ERR_PERM_DENIED, "Operation not permitted - '" + id + "' in use."];
        }
        //console.log("_ensureExclusiveAccess done", Date.now());
    };

    return obj;
}();

module.exports = tasks_func;

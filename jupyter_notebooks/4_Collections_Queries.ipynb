{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Collections and Queries in DataFed\n",
    "In this notebook, we will be going over creating Collections, viewing contained items, organizing Collections, downloading Collections, and searching for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we begin:\n",
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datafed.CommandLib import API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the DataFed API and set ``context`` to the Training project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api = API()\n",
    "df_api.setContext(\"p/trn001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> Reset this variable to your username or Globus ID so that you work within your own collection by default </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_collection = \"breetju\"  # Name of this user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview:\n",
    "In this notebook, let us assume that we are working on a machine learning problem aimed at putting together training data for a machine learning model. For illustration purposes, we will assume that we aim to train a classifier for classifying animals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Collection\n",
    "First, let us create a collection to hold all our data. \n",
    "\n",
    "We will be using the ``collectionCreate()`` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_resp = df_api.collectionCreate(\n",
    "    \"Image classification training data\", parent_id=parent_collection\n",
    ")\n",
    "print(coll_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we got back a ``CollDataReply`` object. This is somewhat similar to what you get from ``dataCreate()`` we just saw. \n",
    "\n",
    "\n",
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> Extract the ``id`` of this newly created collection: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_coll_id = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate with training data\n",
    "Now that we have a place to put the training data, let us populate this collection with examples of animals\n",
    "### Define a function to generate (fake) training data:\n",
    "We need a function to:\n",
    "* Create a Data Record\n",
    "* Put data into this Data Record\n",
    "\n",
    "For simplicity we will use some dummy data from a public Globus Endpoint This information has been filled in for you via the ``raw_data_path`` variable\n",
    "\n",
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> We have a skeleton function prepared for you along with comments to guide you. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_animal_data(is_dog=True):\n",
    "    # this_animal = \"cat\"\n",
    "    if is_dog:\n",
    "        this_animal = \"dog\"\n",
    "    # To mimic a real-life scenario, we append a number to the animal\n",
    "    # type to denote the N-th example of a cat or dog. In this case, we\n",
    "    # use a random integer.\n",
    "    # suffix = \"_\" + str(random.randint(1, 1000))\n",
    "\n",
    "    # Create the record here:\n",
    "\n",
    "    # Extract the ID of the Record:\n",
    "\n",
    "    # path to the file containing the (dummy) raw data\n",
    "    raw_data_path = (\n",
    "        \"sdss#public/uufs/chpc.utah.edu/common/home/sdss/dr10/\"\n",
    "        \"apogee/spectro/data/55574/55574.md5sum\"\n",
    "    )\n",
    "\n",
    "    # Put the raw data into the record you just created:\n",
    "\n",
    "    # Only return the ID of the Data Record you created:\n",
    "    return this_rec_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate 5 examples of cats and dogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_records = list()\n",
    "dog_records = list()\n",
    "for _ in range(5):\n",
    "    dog_records.append(generate_animal_data(is_dog=True))\n",
    "for _ in range(5):\n",
    "    cat_records.append(generate_animal_data(is_dog=False))print(cat_records)print(dog_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing items in a Collection:\n",
    "Let us take a look at the training data we have assembled so far using the ``colectionItemsList()`` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_list_resp = df_api.collectionItemsList(train_coll_id)\n",
    "print(coll_list_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Note </span>\n",
    "> <span style=\"color:blue\"> If we had several dozens, hundreds, or even thousands of items in a Collection, we would need to call ``collectionItemsList()`` multiple times by stepping up the ``offset`` keyword argument each time to get the next “page” of results. </span>\n",
    "\n",
    "### <span style=\"color:green\"> Discussion </span>\n",
    "<span style=\"color:green\"> Let's say that we are only interested in finding records that have cats in this (potentially) large collection of training data. How do we go about doing that? </span>\n",
    "\n",
    "# Data Query / Search\n",
    "### <span style=\"color:red\"> Caution </span>\n",
    "> <span style=\"color:red\"> Search vocabulary is likely to change with newer versions of DataFed </span>\n",
    "\n",
    "Use the DataFed web interface to:\n",
    "* Search for cats\n",
    "* Specifically in your collection\n",
    "* Save the query\n",
    "\n",
    "### <span style=\"color:blue\"> Note </span>\n",
    "> <span style=\"color:blue\"> Saved queries can be found in the bottom of the navigation (left) pane under ``Project Data`` and ``Saved Queries`` </span>\n",
    "\n",
    "# Find saved queries:\n",
    "We can list all saved queries via ``queryList()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_resp = df_api.queryList()\n",
    "print(ql_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we again recieved the familiar ``ListingReply`` object as the response\n",
    "\n",
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> Get the ``id`` of the desired query out of the response: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_id = ?\n",
    "print(query_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the saved query\n",
    "Use the ``queryView()`` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.queryView(query_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the saved query\n",
    "Use the ``queryExec()`` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_resp = df_api.queryExec(query_id)\n",
    "print(query_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet again, we get back the ``ListingReply`` message. \n",
    "\n",
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> Extract just the ``id``s from each of the items in the message: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get IDs from query result\n",
    "cat_rec_ids = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have the ground truth in ``cat_records``. Is this the same as what we got from the query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(cat_rec_ids) == set(cat_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating cats from dogs\n",
    "Our goal now is to gather all cat Data Records into a dedicated Collection\n",
    "\n",
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> Create a new collection to hold the Cats record </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> Extract the ``id`` for this Collection: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_coll_id = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Items to Collection\n",
    "Now let us add only the cat Data Records into this new collection using the ``collectionItemsUpdate()`` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cup_resp = df_api.collectionItemsUpdate(cat_coll_id, add_ids=cat_rec_ids)\n",
    "print(cup_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike most DataFed functions, this function doesn't really return much\n",
    "\n",
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> View the contents of the Cats Collection to make sure that all Cat Data Records are present in this Collection </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> View the contents of the main training data Collection: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Note </span>\n",
    "> <span style=\"color:blue\"> Data Records can exist in **multiple** Collections just like video or songs can exist on multiple playlists </span>\n",
    "\n",
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> Remove the cat Data Records from the training data collection. They already exist in the \"Cats\" Collection </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> View the contents of the training data Collection. Do you see the individual cat Data Records in this collection? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search or Organize?\n",
    "If you could always search for your data, what is the benefit to organizing them into collections?\n",
    "\n",
    "# Download entire Collection\n",
    "\n",
    "### <span style=\"color:blue\"> Note </span>\n",
    "> <span style=\"color:blue\"> Recall that DataFed can download arbitrarily large number of Records regardless of the physical locations of the DataFed repositories containing the data. </span>\n",
    "\n",
    "Let us first make sure we don't already have a directory with the desired name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir = \"./cat_data\"\n",
    "\n",
    "if os.path.exists(dest_dir):\n",
    "    import shutil\n",
    "\n",
    "    shutil.rmtree(dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Exercise </span>\n",
    "<span style=\"color:green\"> Download the entire Cat Collection with a single DataFed function call </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that we did infact download the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(dest_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\"> Optional Exercise </span>\n",
    "<span style=\"color:green\">1. Create a new Collection to hold the simulation data you created in the previous notebook <br>2. Use the functions you saw above to ensure that the Data Records only exist in the Simulation Collection </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

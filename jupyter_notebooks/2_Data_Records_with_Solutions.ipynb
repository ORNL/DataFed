{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Records\n",
    "In this notebook, we will be going over how to create, add metadata and other contextual information, edit, establish relationships between ``Data Records`` - the fundamental unit in DataFed\n",
    "\n",
    "## Setting up:\n",
    "Just as in the previous notebook, we start be instantiating the ``datafed.CommandLib.API`` class to communicate with DataFed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datafed.CommandLib import API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "df_api = API()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying context:\n",
    "Since we want to work within the ``context`` of the Training Project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_api.setContext(\"p/trn001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, you will be working within your own private collection whose ``alias`` is the same as your DataFed username.\n",
    "\n",
    "### <span style=\"color:green\"> Exercise: </span>\n",
    "<span style=\"color:green\"> Enter your username into the ``parent_collection`` variable </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_collection = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Data Records:\n",
    "Data Records can hold a whole lot of contextual information about the raw data in them. One key component is the scientific metadata. Ideally, we would get this metadata from the headers of the raw data file or some other log file that was generated along with the raw data. \n",
    "\n",
    "### <span style=\"color:blue\"> Note </span>\n",
    "> <span style=\"color:blue\"> DataFed expects scientific metadata to be specified **like** a python dictionary. </span>\n",
    "\n",
    "For now, let's set up some dummy metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"a\": 4,\n",
    "    \"b\": [1, 2, -4, 7.123],\n",
    "    \"c\": \"Something important\",\n",
    "    \"d\": {\"x\": 14, \"y\": -19},  # Can use nested dictionaries\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\"> Note </span>\n",
    "> <span style=\"color:blue\"> DataFed **currently** encodes metadata in JSON strings. The next version will accept python dictonaries as is.</span>\n",
    "\n",
    "For now, we will need to convert the metadata to a JSON string using the ``dumps()`` function in the ``json`` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dumps(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `dataCreate()` function to make our new record, and the `json.dumps()` function to format the python dictionary to JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parent_collection The parent collection, whose alias is your username\n",
    "dc_resp = df_api.dataCreate(\n",
    "    \"my important data\",\n",
    "    metadata=json.dumps(parameters),\n",
    "    parent_id=parent_collection,\n",
    ")\n",
    "dc_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> **Note:** </span> \n",
    "> <span style=\"color:blue\">  In the future, the ``dataCreate()`` function would by default return only the ``ID`` of the record instead of such a verbose response if it successfully created the Data Record. We expect to be able to continue to get this verbose response through an optional argument. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\">  Exercise: </span>\n",
    "<span style=\"color:green\"> Extract the ``ID`` of the data record from the message returned from ``dataCreate()`` for future use: </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_id = dc_resp[0].data[0].id\n",
    "print(record_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Records and the information in them are not static and can always be modified at any time\n",
    "## Updating Data Records\n",
    "Let's add some additional metadata and change the title of our record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\"appended_metadata\": True}\n",
    "du_resp = df_api.dataUpdate(\n",
    "    record_id,\n",
    "    title=\"Some new title for the data\",\n",
    "    metadata=json.dumps(metadata),\n",
    ")\n",
    "print(du_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> **Note:** </span> \n",
    "> <span style=\"color:blue\"> In the future, the dataUpdate() command would return only an acknowledgement of the successful execution of the data update. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Data Records\n",
    "We can get full information about a data record  including the complete metadata via the ``dataView()`` function. Let us use this function to verify that the changes have been incorporated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv_resp = df_api.dataView(record_id)\n",
    "print(dv_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\"> **Note:** </span> \n",
    "> <span style=\"color:blue\"> Record metadata is always stored as a JSON string. </span>\n",
    "\n",
    "### <span style=\"color:green\"> Exercise: </span>\n",
    "<span style=\"color:green\"> Try isolating the updated metadata and converting it to a python dictionary. </span>\n",
    "\n",
    "Hint - ``json.loads()`` is the opposite of ``json.dumps()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = json.loads(dv_resp[0].data[0].metadata)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first update, we **merged** new metadata with the existing metadata within the record. However ``dataUpdate()`` is also capable of replacing the metadata as well.\n",
    "\n",
    "### <span style=\"color:green\"> Exercise: </span>\n",
    "<span style=\"color:green\"> Now try to **replace** the metadata. <br><br>Hint: look at the `metadata_set` keyword argument in the docstrings. </span>\n",
    "\n",
    "### <span style=\"color:blue\"> Tip: </span>\n",
    "> <span style=\"color:blue\"> With the cursor just past the starting parenthesis of ``dataUpdate(``, simultaneously press the ``Shift`` and ``Tab`` keys once, twice, or four times to view more of the documentation about the function. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_metadata = {\"key\": \"value\", \"E\": \"mc^2\"}\n",
    "du_resp = df_api.dataUpdate(record_id, metadata=json.dumps(new_metadata), metadata_set=True)\n",
    "dv_resp = df_api.dataView(record_id)\n",
    "print(json.loads(dv_resp[0].data[0].metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provenance\n",
    "Along with in-depth, detailed scientific metadata describing each data record, DataFed also provides a very handy tool for tracking data provenance, i.e. recording the relationships between Data Records which can be used to track the history, lineage, and origins of a data object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Exercise: </span>\n",
    "<span style=\"color:green\"> Create a new record meant to hold some processed version of the first data record. <br> **Caution**: Make sure to create it in the correct Collection.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = {\"hello\": \"world\", \"counting\": [1, 2, 3, 4]}\n",
    "\n",
    "dc2_resp = df_api.dataCreate(\n",
    "    \"Subsequent Record\",\n",
    "    metadata=json.dumps(new_params),\n",
    "    parent_id=parent_collection,\n",
    ")\n",
    "\n",
    "clean_rec_id = dc2_resp[0].data[0].id\n",
    "print(clean_rec_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Relationships\n",
    "Now that we have two records, we can specify the second record's relationship to the first by adding a **dependency** via the ``deps_add`` keyword argument of the ``dataUpdate()`` function.\n",
    "\n",
    "### <span style=\"color:blue\"> Note: </span>\n",
    "> <span style=\"color:blue\"> As the documentation for ``dataUpdate()`` will reveal, dependencies must be specified as a ``list`` of relationships. Each relationship is expressed as a ``list`` where the first item is a dependency type (a string) and the second is the data record (also a string). </span>\n",
    "\n",
    "DataFed currently supports three relationship types:\n",
    "* `der` - Is derived from\n",
    "* `comp` - Is comprised of\n",
    "* `ver` - Is new version of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_resp = df_api.dataUpdate(clean_rec_id, deps_add=[[\"der\", record_id]])\n",
    "print(dep_resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Exercise: </span>\n",
    "<span style=\"color:green\"> Take a look at the records on the DataFed Web Portal in order to see a graphical representation of the data provenance. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\"> Exercise: </span>\n",
    "<span style=\"color:green\">1. Create a new data record to hold a figure in your journal article. <br>2. Extract the record ID. <br>3. Now establish a provenance link between this figure record and the processed data record we just created. You may try out a different dependency type if you like. <br>4. Take a look at the DataFed web portal to see the update to the Provenance of the records</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "reply = df_api.dataCreate(\"Figure 1\", parent_id=parent_collection)\n",
    "# 2\n",
    "fig_id = reply[0].data[0].id\n",
    "# 3\n",
    "provenance_link = df_api.dataUpdate(fig_id, deps_add=[(\"comp\", clean_rec_id)])\n",
    "print(provenance_link[0].data[0])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
